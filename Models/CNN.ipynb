{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **import the library **"
      ],
      "metadata": {
        "id": "x3Vkh8IQyLl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.isri import ISRIStemmer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "metadata": {
        "id": "G9ydT7nOxf0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pLIs-MKzSsmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Download required resources\n",
        "nltk.download('stopwords')\n",
        "arabic_stopwords = set(stopwords.words(\"arabic\"))\n",
        "stemmer = ISRIStemmer()\n",
        "\n",
        "### Preprocess function\n",
        "def preprocess(text):\n",
        "    text = re.sub(r'[^\\u0621-\\u064A\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    tokens = [stemmer.stem(word) for word in text.split() if word not in arabic_stopwords]\n",
        "    return tokens\n",
        "\n",
        "###Load train and test datasets\n",
        "train_df = pd.read_csv(\"/content/Algerian Review.csv\").dropna(subset=['Commentaire', 'Statut'])\n",
        "train_df['Statut'] = train_df['Statut'].replace({0:'Neutre',1:'Positif',-1:'NÃ©gatif'})\n",
        "test_df = pd.read_csv(\"/content/test.csv\").dropna(subset=['Commentaire'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_RBRWGsxf3-",
        "outputId": "e35a7760-b515-4afc-8b87-addab5bb20d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre procecing"
      ],
      "metadata": {
        "id": "rdu1j4fM0CGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "train_df['label'] = label_encoder.fit_transform(train_df['Statut'])\n",
        "\n",
        "###Preprocess all comments\n",
        "train_df['tokens'] = train_df['Commentaire'].astype(str).apply(preprocess)\n",
        "test_df['tokens'] = test_df['Commentaire'].astype(str).apply(preprocess)\n",
        "\n",
        "###Build vocabulary\n",
        "vocab = {'<PAD>': 0, '<UNK>': 1}\n",
        "for tokens in train_df['tokens']:\n",
        "    for token in tokens:\n",
        "        if token not in vocab:\n",
        "            vocab[token] = len(vocab)\n",
        "\n",
        "###Encode tokens\n",
        "def encode(tokens):\n",
        "    return [vocab.get(token, vocab['<UNK>']) for token in tokens]\n",
        "\n",
        "train_df['encoded'] = train_df['tokens'].apply(encode)\n",
        "test_df['encoded'] = test_df['tokens'].apply(encode)\n",
        "\n",
        "###Dataset class\n",
        "class ArabicDataset(Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = [torch.tensor(e, dtype=torch.long) for e in encodings]\n",
        "        self.labels = labels if labels is None else torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.labels is not None:\n",
        "            return self.encodings[idx], self.labels[idx]\n",
        "        else:\n",
        "            return self.encodings[idx]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    if isinstance(batch[0], tuple):\n",
        "        texts, labels = zip(*batch)\n",
        "        texts = pad_sequence(texts, batch_first=True)\n",
        "        labels = torch.stack(labels)\n",
        "        return texts, labels\n",
        "    else:\n",
        "        texts = pad_sequence(batch, batch_first=True)\n",
        "        return texts\n",
        "###Dataloaders\n",
        "train_dataset = ArabicDataset(train_df['encoded'].tolist(), train_df['label'].tolist())\n",
        "test_dataset = ArabicDataset(test_df['encoded'].tolist())\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n"
      ],
      "metadata": {
        "id": "MmAUxrovxf7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### build the moodele"
      ],
      "metadata": {
        "id": "NpI8zvTc1k1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "### CNN Model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CNNTextClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_classes, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "\n",
        "        self.conv1 = nn.Conv1d(embed_dim, 128, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(embed_dim, 128, kernel_size=4, padding=2)\n",
        "        self.conv3 = nn.Conv1d(embed_dim, 128, kernel_size=5, padding=2)\n",
        "\n",
        "        self.batch_norm = nn.BatchNorm1d(128 * 3)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc1 = nn.Linear(128 * 3, 256)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: [batch_size, sequence_length]\n",
        "        x = self.embedding(x)  # -> [B, T, E]\n",
        "        x = x.permute(0, 2, 1)  # -> [B, E, T]\n",
        "\n",
        "        x1 = torch.relu(self.conv1(x))  # -> [B, 128, T]\n",
        "        x2 = torch.relu(self.conv2(x))  # -> [B, 128, T]\n",
        "        x3 = torch.relu(self.conv3(x))  # -> [B, 128, T]\n",
        "\n",
        "        x1 = torch.max(x1, dim=2)[0]  # Global Max Pooling -> [B, 128]\n",
        "        x2 = torch.max(x2, dim=2)[0]\n",
        "        x3 = torch.max(x3, dim=2)[0]\n",
        "\n",
        "        x = torch.cat([x1, x2, x3], dim=1)  # -> [B, 128*3]\n",
        "        x = self.batch_norm(x)\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.fc2(x)\n",
        "\n",
        "\n",
        "### Model setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = CNNTextClassifier(vocab_size=len(vocab), embed_dim=100, num_classes=3).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
      ],
      "metadata": {
        "id": "-X2G7nwSxf-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###Training loop\n",
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    for texts, labels in train_loader:\n",
        "        texts, labels = texts.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(texts)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"âœ… Epoch {epoch+1} done\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00OnZZxSxgBD",
        "outputId": "40af461c-b70e-449b-9274-7e98429fbc77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 1 done\n",
            "âœ… Epoch 2 done\n",
            "âœ… Epoch 3 done\n",
            "âœ… Epoch 4 done\n",
            "âœ… Epoch 5 done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### evaluation"
      ],
      "metadata": {
        "id": "dhzKS12TzsDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Evaluation\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for texts, labels in train_loader:\n",
        "        texts = texts.to(device)\n",
        "        output = model(texts)\n",
        "        preds = torch.argmax(output, dim=1).cpu().numpy()\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels.numpy())\n",
        "\n",
        "print(\"ðŸ“Š Accuracy:\", accuracy_score(all_labels, all_preds))\n",
        "print(classification_report(all_labels, all_preds, target_names=label_encoder.classes_))\n",
        "\n",
        "### Predict on test set\n",
        "predictions = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = batch.to(device)\n",
        "        outputs = model(batch)\n",
        "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "        predictions.extend(preds)\n",
        "\n",
        "#### Save prediction\n",
        "test_df['Statut'] = label_encoder.inverse_transform(predictions)\n",
        "test_df[['ID', 'Statut']].to_csv(\"predicted_test.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDu-x-swxgDt",
        "outputId": "ba639164-c6c1-4d81-dc1c-2182a4c73b4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Accuracy: 0.8037593984962406\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Neutre       0.74      0.99      0.85      2934\n",
            "     NÃ©gatif       0.99      0.67      0.80      1819\n",
            "     Positif       0.93      0.24      0.38       567\n",
            "\n",
            "    accuracy                           0.80      5320\n",
            "   macro avg       0.89      0.64      0.68      5320\n",
            "weighted avg       0.85      0.80      0.78      5320\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: i wana download the modele\n",
        "\n",
        "# Define the filename for saving the model\n",
        "model_filename = 'cnn_text_classifier11.pth'\n",
        "\n",
        "# Save the model state dictionary\n",
        "torch.save(model.state_dict(), model_filename)\n",
        "\n",
        "print(f\"Model saved to {model_filename}\")\n",
        "\n",
        "# To download the file in Google Colab\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download(model_filename)\n",
        "except ImportError:\n",
        "  pass # Not running in Colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "yucIktd3xgJd",
        "outputId": "9673b156-f673-4a32-f77e-72da58b77417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to cnn_text_classifier11.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_81941625-5811-4366-aa8e-19c0e625b217\", \"cnn_text_classifier11.pth\", 2770366)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: i wana dowlnload also the tokinizer\n",
        "\n",
        "import pickle\n",
        "\n",
        "# Define the filename for saving the tokenizer\n",
        ".\n",
        "\n",
        "# Save the vocab dictionary\n",
        "with open(tokenizer_filename, 'wb') as f:\n",
        "    pickle.dump(vocab, f)\n",
        "\n",
        "print(f\"Tokenizer (vocab) saved to {tokenizer_filename}\")\n",
        "\n",
        "# To download the file in Google Colab\n",
        "try:\n",
        "  files.download(tokenizer_filename)\n",
        "except ImportError:\n",
        "  pass # Not running in Colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "9DKm31JKxgMG",
        "outputId": "59a5b249-3147-440e-c72d-566e51a77d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer (vocab) saved to vocab.pkl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_72a383f4-8a1a-4a51-9dbc-55ab87193bda\", \"vocab.pkl\", 161592)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: i waana download label encoder\n",
        "\n",
        "tokenizer_filename = 'tokenizer_vocab.pkl'\n",
        "# Save the label encoder\n",
        "with open('label_encoder.pkl', 'wb') as f:\n",
        "  pickle.dump(label_encoder, f)\n",
        "\n",
        "print(\"Label encoder saved to label_encoder.pkl\")\n",
        "\n",
        "try:\n",
        "  files.download('label_encoder.pkl')\n",
        "except ImportError:\n",
        "  pass # Not running in Colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "9WnooowXxgPH",
        "outputId": "9702eee8-1055-42ab-db30-8febbe52beed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label encoder saved to label_encoder.pkl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3a055764-e224-4e24-aaa7-16571b30bf32\", \"label_encoder.pkl\", 273)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mQ3PRsGgxgRx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
